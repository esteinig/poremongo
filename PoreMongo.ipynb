{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoreMongo\n",
    "\n",
    "\n",
    "#### Requirements\n",
    "---\n",
    "\n",
    "PoreMongo is written for Python > 3.6. For now:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/esteinig/poremongo\n",
    "cd poremongo\n",
    "pip install .\n",
    "```\n",
    "\n",
    "#### Configuration\n",
    "---\n",
    "\n",
    "The PoreMongo configuration JSON file (default: `poremongo.json`) helps to keep some basic and password sensitive parameters under user access only (make sure to change file permissions) and includes one mandatory entry - the URI to connect to MongoDB - such that:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"uri\": \"mongodb://<username>:<pwd>@<server>:<port>/poremongo-nb\"\n",
    "}\n",
    "```\n",
    "\n",
    "You can also add another nested entry to this in order to specify the SSH configuration to use, if you want to access files indexed on a remote server, such as your high-performance computer where the data is in storage. Currently this is only available for a single remote storage location. The SSH connection has to be explicitly established in the `PoreMongo` class, but more on that later. An example would be:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"uri\": \"mongodb://<username>:<pwd>@<server>:<port>/poremongo-nb\",\n",
    "  \"ssh\": {\n",
    "    \"user\": \"<user>\",\n",
    "    \"password\": \"<ssh_pwd>\",\n",
    "    \"server\": \"<server>\",\n",
    "    \"port\": \"<port>\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "#### PoreMongo API\n",
    "---\n",
    "\n",
    "The next few sections walk through an object oriented application of PoreMongo in your Python code. Let's see how we can connect to the database and index Fast5 files from multiple sequencing runs, populating the database for the other operations like sampling and extracting signal level data.\n",
    "\n",
    "You can use a config dictionary or the JSON config file.\n",
    "\n",
    "```python\n",
    "config = {\n",
    "    \"uri\": \"mongodb://<username>:<pwd>@<server>:<port>/poremongo-nb\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import poremongo\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "from poremongo.models import Fast5\n",
    "\n",
    "# Using poremongo.nb.json configuration file\n",
    "pongo = poremongo.PoreMongo(config=config, verbose=False) # silent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I usually explicitly connect and disconnect later from the database for clarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pongo.connect()  # pongo.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing and tagging Fast5 files in storage\n",
    "---\n",
    "\n",
    "We are connected! Excellent. Now the first step is to index some data paths on your local system. For the purpose of this demonstrations we will use the absolute paths for the test files as `tests/data/human_1` and `tests/data/tb_1` to write a demonstration function that indexes (without multiprocessing) and then tags the files according to organism (n = 10 for Human, n = 10 for TB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_and_tag():\n",
    "    \"\"\"Wrapper for indexing and tagging test files in tests/data.\"\"\"\n",
    "    \n",
    "    path_1 = os.path.abspath(\"tests/data/human_1\")\n",
    "    path_2 = os.path.abspath(\"tests/data/tb_1\")\n",
    "    \n",
    "    pongo.index(index_path=path_1, recursive=True, insert=True, batch_size=5, ncpu=1, reconnect=True)\n",
    "    pongo.tag(path_query=path_1, tags=(\"Human\", \"R9.4\", \"Notebook\"), recursive=True)\n",
    "    \n",
    "    pongo.index(index_path=path_2, recursive=True, insert=True, batch_size=5, ncpu=1, reconnect=True)\n",
    "    pongo.tag(path_query=path_2, tags=(\"TB\", \"R9.4\", \"Notebook\"), recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also assign tags for pass and fail directories, since a recursive path_query checks for: `path_query in fast5.path` - the following assigns the tag \"pass\" to all documents in the database that contain \"/pass/\" in their file path. On Windows, the query would be \"\\\\\\pass\\\\\\\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pongo.tag(path_query=\"/pass/\", tags=(\"pass\"), recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "#### Recursive search and insert to Database\n",
    "---\n",
    "\n",
    "Inserts into the database are always performed in batches of `batch_size` Fast5.\n",
    "\n",
    "There is two important parameters: a boolean for `recursive` search through the directories and subdirectories. Recursive searches are a bit slower. For many hundreds of thousands of files, you should anticipate several hours of indexing. \n",
    "\n",
    "`Insert` will speed up indexing by inserting file paths that are not present in the database already - it will break the indexing process if you are re-indexing! Models in the database have a unique file path, so that files are not indexed multiple times. \n",
    "\n",
    "If you want to re-index the current file paths for whatever reason, the only way at the moment is to manually delete them by dropping the collection, for instance in Robomongo. There should be a fix for that soon - the reason here is that for some reason the indexing cannot be done through batch upserts in `PyMongo`, which would otherwise simply update the path of the Fast5.\n",
    "\n",
    "#### Multiprocessing\n",
    "---\n",
    "\n",
    "Other important parameters include `ncpu` for multiprocessing inserts, which will first aggregate the files after scanning directories into batches and `insert` them into the database across multiple processors. **This significantly speeds up the indexing process and is essentially required for large file collections**.\n",
    "\n",
    "You need to have `insert = True` for this to work. Multiprocess inserts connect to the database on multiple `PyMongo` clients, so if you do not want to reconnect manually to the main client initiated above (`connect`), also make sure to specify `reconnect = True`.\n",
    "\n",
    "#### Tags\n",
    "---\n",
    "\n",
    "Tagging is conducted on indexed collections. Usually you would pass the same indexing path to the `path_query` parameter which then performs a query for the path in the database models (recursive tagging searches for the path contained `in` the file path).\n",
    "\n",
    "Last, we display the tags present in the database (currently limited to the most frequent tags for clarity, n = 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comment this out when repeating the notebook, since you do not want\n",
    "# to insert the same models into the database (throws NotUnique error)\n",
    "\n",
    "index_and_tag() # If on Windows make sure to wrap multiprocessing into if \"__name__\" == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pongo.display(\"tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying and sampling in PoreMongo\n",
    "---\n",
    "\n",
    "Alright, now that we have indexed and tagged our read collections we can query, sample and extract the Fast5 files from the MongoDB. Sampling uses aggregation pipelines and returns the Fast5 model objects defined via `Mongoengine`. These objects themselves have methods that may be useful to your operations, such as opening and returning the signal value arrays. \n",
    "\n",
    "Sampled objects can then be additionally filtered (in memory, so make sure it's not necessarily trillions of files) and passed along to other methods such as the `copy` method. This creates a copy of the Fast5 files from local storage into a directory of your choice. Copies can also be handled via SSH, if an entry for SSH configuration is present in the config dictionary / JSON (see below).\n",
    "\n",
    "#### Queries\n",
    "---\n",
    "\n",
    "Let's first query the database for some Fast5 file objects. Queries can be raw `PyMongo` query dictionaries, or lists of queries that provide a super simple interface to the query process with `PyMongo`. Let's walk through some examples for `tag`, `path` and `name` queries using the low-level `query` method in `PoreMongo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define some queries:\n",
    "\n",
    "tag_query_1 = \"TB\"                   # Single tag query\n",
    "tag_query_2 = [\"TB\", \"Human\"]        # Multiple tag query\n",
    "tag_query_3 = [\"TB\", \"Notebook\"]     # Multiple tag query\n",
    "\n",
    "# Query the database, specify the logic with which to chain query items, if input is a list:\n",
    "\n",
    "result_1 = pongo.query(tag_query=tag_query_1)\n",
    "result_2 = pongo.query(tag_query=tag_query_2, query_logic=\"AND\")\n",
    "result_3 = pongo.query(tag_query=tag_query_2, query_logic=\"OR\")\n",
    "result_4 = pongo.query(tag_query=tag_query_3, query_logic=\"AND\")\n",
    "result_5 = pongo.query(tag_query=tag_query_3, query_logic=\"OR\")\n",
    "\n",
    "\n",
    "# Checking the number of query results:\n",
    "\n",
    "print(f\"\"\"\n",
    "Number of returned Fast5 objects:\n",
    "\n",
    "    Query 1 = {len(result_1)} (TB files only)\n",
    "    Query 2 = {len(result_2)}  (No files, \"TB AND Human\")\n",
    "    Query 3 = {len(result_3)} (TB and Human files, \"TB OR Human\")\n",
    "    Query 4 = {len(result_4)} (TB files, \"TB AND Notebook\")\n",
    "    Query 5 = {len(result_5)} (TB and Human files, \"TB OR Notebook\")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Checking content of the returned results:\n",
    "print(\"\\nFast5 model objects from query 5:\\n\")\n",
    "\n",
    "print(result_5)\n",
    "\n",
    "# Checking tags of the last result:\n",
    "print(\"Checking tags of query 5:\\n\")\n",
    "\n",
    "for fast5 in result_5:\n",
    "    print(fast5.tags)\n",
    "\n",
    "# What can we do with Fast5 model objects?\n",
    "\n",
    "fast5 = result_1[0] # single Fast5 model object\n",
    "\n",
    "# Open file and extract the singal array, template strand only, 1D\n",
    "\n",
    "signal_data = fast5.get_reads(template=True)\n",
    "\n",
    "sliced_signal_data = fast5.get_reads(template=True, window_size=400, window_step=40)\n",
    "\n",
    "\n",
    "print(\"\\nRead (signal array) data extraction:\")\n",
    "print(f\"\"\"\n",
    "Signal strand array, NumPy:             {signal_data} \n",
    "Signal template length:                 {len(signal_data[0])}   \n",
    "Signal sliced, shape:                   {sliced_signal_data.shape}\n",
    "\"\"\")\n",
    "\n",
    "# Get model attributes as JSON:\n",
    "\n",
    "fast5_attr = fast5.to_json()\n",
    "print(\"Fast5 model attributes in JSON:\\n\")\n",
    "\n",
    "obj = json.loads(fast5_attr)  \n",
    "pprint(obj)\n",
    "\n",
    "# Raw query on IMB14 start of file names of TB:\n",
    "\n",
    "raw_query_1 = {\"name\": {\"$regex\": \".*IMB14.*\"}}\n",
    "\n",
    "raw_result_1 = pongo.query(raw_query=raw_query_1)\n",
    "\n",
    "print(f\"\\nTB test files IMB14* -- {len(raw_result_1)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random samples and file copy\n",
    "---\n",
    "\n",
    "Sample random models from the database and extract them by making copies (or symlinks) into a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pass all Fast5 model objects in database to tag sample aggregation pipeline\n",
    "sample_1 = pongo.sample(Fast5.objects, tags=[\"Human\"], limit=5, proportion=None, unique=False, exclude=None)  # Return 5\n",
    "\n",
    "fast5_queried = result_1  # From query above, TB only\n",
    "\n",
    "sample_2 = pongo.sample(fast5_queried, tags=[\"Human\"], limit=5, proportion=None, unique=False, exclude=None)  # Return 0, no Human\n",
    "sample_3 = pongo.sample(fast5_queried, tags=[\"TB\"], limit=7, proportion=None, unique=False, exclude=None)  # Return 7, no Human\n",
    "\n",
    "print(f\"\\nNumber of sample results: sample_1: {len(sample_1)}, sample_2: {len(sample_2)}, sample_3: {len(sample_3)}\\n\")\n",
    "\n",
    "print(\"Tags from sample_1:\\n\")\n",
    "\n",
    "for f5 in sample_1:\n",
    "    print(f5.tags)\n",
    "    \n",
    "print(\"\\n\")\n",
    "\n",
    "# It is also possible to pass pre-filtered / queried Fast5 objects to sample method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query tag combinations + labels\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to sample Fast5 by tags for successive labels (0, 1, 2, ...), input is a nested list\n",
    "\n",
    "labels_query_1 = [[\"TB\", \"R9.4\"], [\"Human\"]] #  TB & R9.4 (label 0), Human (label 1)\n",
    "\n",
    "def sample_by_label(sample_query, outdir=None, prop=None):\n",
    "    \n",
    "    \"\"\"Generates a random sample of Fast5 objects for each tag entry in the sample_query.\n",
    "    Sample randomly from database across tags and enumerate by label for each element in\n",
    "    a nested input tag query; copy or make a CSV file of Fast5 paths in PoreMongo.\n",
    "    \"\"\"\n",
    "\n",
    "    sampled = []\n",
    "    labels = []\n",
    "    # Sample for each tag list in sample query, assign label 0, 1, ...\n",
    "    for label, tags in enumerate(sample_query):\n",
    "        sample = pongo.sample(Fast5.objects, tags=tags, limit=5, proportion=prop)\n",
    "        sampled += sample\n",
    "        labels += [label for _ in sample]\n",
    "    \n",
    "    print(\"\\n\", sampled, \"\\n\")\n",
    "    print(labels, \"\\n\")\n",
    "    \n",
    "    if outdir:\n",
    "        pongo.copy(sampled, outdir=outdir, ncpu=1, iterate=False)\n",
    "    else:\n",
    "        pongo.to_csv(sampled, labels=labels, out_file=\"tmp/tmp.csv\")\n",
    "    \n",
    "    # Object IDs of random sample\n",
    "    ids = [str(fast5._id) for fast5 in sampled]\n",
    "    \n",
    "    pprint(ids)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    return sampled, labels\n",
    "\n",
    "sample_by_label(labels_query_1, outdir=\"tmp/random_1\")\n",
    "sample_by_label(labels_query_1, outdir=\"tmp/random_2\")\n",
    "\n",
    "shutil.rmtree(\"tmp\")  # Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proportional sampling\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_1, labels_1 = sample_by_label(labels_query_1, outdir=\"tmp/random_1\", prop=None)\n",
    "\n",
    "sampled_2, labels_2 = sample_by_label(labels_query_1, outdir=\"tmp/random_2\", prop=\"equal\")\n",
    "\n",
    "shutil.rmtree(\"tmp\")  # Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Simulation\n",
    "---\n",
    "\n",
    "First query a subset of the data (all Fast5 models with tag TB). Then group the subset into Fast5 runs with the same experiment start time. There is one run grouping all TB files. Use the run ids to perform a query to the database and obtain the fast5 models belonging to this run (same as the initial query). Schedule a run by sorting the models by read completion times and scaling for speedup of the simulation. The simulation copies reads in to the output directory with time ibntervals according to the intervals between the read completions times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform query for human data only to limit run groups:\n",
    "fast5 = pongo.query(tag_query=\"TB\")\n",
    "\n",
    "# Extract run groups by start timestamp:\n",
    "runs = pongo.group_runs(fast5)\n",
    "\n",
    "print(\"\\n\")\n",
    "pprint(runs)\n",
    "\n",
    "print(\"\\nExtracting Fast models for each run and simulating file copies with Taeper.\\n\")\n",
    "# Query for Fast5 models from run group:\n",
    "fast5 = pongo.query(raw_query={\"_id\": {\"$in\": runs[1488336230][\"fast5\"]}})\n",
    "\n",
    "# Schedule a run of the based on sorted end times of reads in Fast5 files\n",
    "# close the scheduler after timeout of 20 seconds, to complete process.\n",
    "pongo.schedule_run(fast5, scale=10000, outdir=\"run_sim_1\", timeout=20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(\"run_sim_1\")  # Clean, comment out if running watchdog (see below)\n",
    "\n",
    "pongo.disonnect()  # Don't forget to disconnect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watchdog with callback or index to PoreMongo\n",
    "---\n",
    "\n",
    "In a separate notebook or terminal, run Pomoxis async watchdog on a directory. You can repeat the above cell after commenting the call to shutil.rmtree, in conjunction with the callback defined below to print file names as they are copied into the simulation directory:\n",
    "\n",
    "*Do not run.*\n",
    "\n",
    "```python\n",
    "import os\n",
    "import time\n",
    "\n",
    "from poremongo import PoreMongo\n",
    "\n",
    "pongo = PoreMongo()\n",
    "\n",
    "def callback(fpath):\n",
    "    \n",
    "    print(f\"{time.time()} file={os.path.basename(fpath)}\")\n",
    "\n",
    "watcher = pongo.watch(path=\"run_sim_1\", callback=callback, index=False)\n",
    "\n",
    "# Not implemented yet: index = True\n",
    "\n",
    "# Close async observer with watcher.close()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSH Transfer\n",
    "---\n",
    "\n",
    "*Do not run.*\n",
    "\n",
    "```python\n",
    "import shutil\n",
    "\n",
    "from poremongo import PoreMongo\n",
    "from poremongo.models import Fast5\n",
    "\n",
    "# When creating instance of PoreMongo pass dict with SSH config:\n",
    "\n",
    "config = {\n",
    "  \"uri\": \"mongodb://<username>:<pwd>@<server>:<port>/poremongo-nb\",\n",
    "  \"ssh\": {\n",
    "    \"user\": \"<user>\",\n",
    "    \"password\": \"<ssh_pwd>\",\n",
    "    \"server\": \"<server>\",\n",
    "    \"port\": \"<port>\"\n",
    "  }\n",
    "}\n",
    "\n",
    "pongo = PoreMongo(config=config)\n",
    "\n",
    "# Connect to DB\n",
    "pongo.connect(ssh=True)\n",
    "\n",
    "# Smaple from all Fast5 for Human tag\n",
    "fast5_sample = pongo.sample(Fast5.objects, tags=[\"Human\"], limit=5, proportion=None, unique=False, exclude=None)\n",
    "\n",
    "# SCP copy file into temporary folder\n",
    "for fast5 in fast5_sample:\n",
    "    # Explicitly use SCP client from PoreMongo instance\n",
    "    fast5.get(pongo.scp, out_dir=\"tmp\")  # SCP copies file and modifies fast5.path to tmp/fast5.name\n",
    "    fast5.remove()  # Works only after fast5.path modfied by fast5.get, deletes file tmp/fast5.name\n",
    "\n",
    "pongo.disconnect(ssh=True)\n",
    "\n",
    "shutil.rmtree(\"tmp\")\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:poremongo]",
   "language": "python",
   "name": "conda-env-poremongo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
